---
title: "Text Coding Example Guide"
output: html_notebook
editor_options: 
  chunk_output_type: console
---

FOR GUIDE ON HOW TO CREATE DICTIONARIES, SEE Dictionary Creation Example Guide ARTICLE. THIS GUIDE IS AN EXAMPLE OF HOW TO USE THE PACKAGE STEREOTYPE CONTENT DICTIONARIES.

This guide uses a slightly different (simplified) procedure than the paper (Nicolas, Bai, & Fiske, 2020). Primarily, it uses stemming instead of lemmatizing, it allows for multiple coded per response, and it skips things like spellchecking.

To use, examine and understand the structure of the obituaries file, and format your own text responses in the same format. Then replace the appropriate variables to run your text responses through the code provided to obtain all the dictionaries codings.Make sure all packages are properly installed and loaded.

Alternatively, this code also gives you direct access to the dictionaries in the first lines (e.g., SADCAT::Dictionaries), which you can then transfer to your software or approach of choice. 

To install packages, remove # and run.

```{r}
#install.packages("devtools")
# library(devtools)
# #install_github("gandalfnicolas/SADCAT")
# library(SADCAT)
# #install.packages("quanteda")
# library(quanteda) 
# #install.packages("tidyverse")
# library(tidyverse)
# #install.packages("stringr")
# library(stringr)
# #install.packages("psych")
# library(psych)
```

Load dictionaries: Choose long or short version

```{r}
# Full_Dictionaries = SADCAT::Dictionaries
# 
# Pre_Dictionaries = SADCAT::All.steps_Dictionaries
# 
# 
# Full_Dictionaries = SADCAT::Dictionaries_FT
# 
# Pre_Dictionaries = SADCAT::All.steps_Dictionaries_FT
```

Preprocess dictionaries

```{r}
# Include only dictionary entries that are single words
# Pre_Dictionaries$values0 = as.character(Pre_Dictionaries$values0)
# 
# Pre_Dictionaries = filter(Pre_Dictionaries, !str_count(Pre_Dictionaries$values0, ' ') > 0)
# 
# 
# # Stem, and transform into a format suitable for Quanteda. Here, we are only using high directional values of the dictionaries.
# 
# Pre_Dictionaries2 = Pre_Dictionaries %>%
#   
#   transmute(values0 = char_wordstem(values0, language = quanteda_options("language_stemmer")),
#          
#          Sociability_dic = ifelse(Sociability_dict == 1, values0, ""),
#          Morality_dic = ifelse(Morality_dict ==1, values0,""),
#          Ability_dic = ifelse(Ability_dict ==1, values0,""),
#          Assertiveness_dic = ifelse(Agency_dict ==1, values0,""),
#          Status_dic = ifelse(Status_dict ==1, values0,""),
#          Warmth_dic = ifelse(Warmth_dict ==1, values0,""),
#          Competence_dic = ifelse(Competence_dict ==1, values0,""),
#          Beliefs_dic = ifelse(Beliefs_dict ==1, values0,""),
#          
#          Sociability_dic_hi = ifelse(Sociability_dict_hi == 1, values0, ""),
#          Morality_dic_hi = ifelse(Morality_dict_hi ==1, values0,""),
#          Ability_dic_hi = ifelse(Ability_dict_hi ==1, values0,""),
#          Assertiveness_dic_hi = ifelse(Agency_dict_hi ==1, values0,""),
#          Status_dic_hi = ifelse(Status_dict_hi ==1, values0,""),
#          Warmth_dic_hi = ifelse(Warmth_dict_hi ==1, values0,""),
#          Competence_dic_hi = ifelse(Competence_dict_hi ==1, values0,""),
#          Beliefs_dic_hi = ifelse(Beliefs_dict_hi ==1, values0,""),
#          
#          Sociability_dic_lo = ifelse(Sociability_dict_lo == 1, values0, ""),
#          Morality_dic_lo = ifelse(Morality_dict_lo ==1, values0,""),
#          Ability_dic_lo = ifelse(Ability_dict_lo ==1, values0,""),
#          Assertiveness_dic_lo = ifelse(Agency_dict_lo ==1, values0,""),
#          Status_dic_lo = ifelse(Status_dict_lo ==1, values0,""),
#          Warmth_dic_lo = ifelse(Warmth_dict_lo ==1, values0,""),
#          Competence_dic_lo = ifelse(Competence_dict_lo ==1, values0,""),
#          Beliefs_dic_lo = ifelse(Beliefs_dict_lo ==1, values0,""),
#          
#          Health_dic = ifelse(health_dict ==1, values0,""),
#          Family_dic = ifelse(relative_dict ==1, values0,""),
#          Emotion_dic = ifelse(feeling_dict ==1, values0,""),
#          Nationality_dic = ifelse(Geography_dict ==1, values0,""),
#          Occupation_dic = ifelse(work_dict ==1, values0,""),
#          Appearance_dic = ifelse(Appearance_dict ==1, values0,"")) %>%
#   
#   dplyr::select(-values0)
# 
# 
# Dicts_v2 = 
# lapply(1:length(Pre_Dictionaries2), function(x) Pre_Dictionaries2[[x]][Pre_Dictionaries2[[x]] != ""])
# 
# names(Dicts_v2) = names(Pre_Dictionaries2)
# 
# Dicts_v2 = lapply(Dicts_v2, function(x) x[!is.na(x)])
# 
# 
# #create quanteda dictionaries
# Dicts_v2 = quanteda::dictionary(Dicts_v2)
```

Load example data - examine and change your own data accordingly to match this format.

```{r}
#obituaries = SADCAT::Obituary_data
```

Some preprocessing of the data

```{r}
# obituaries$Beliefs = as.numeric(obituaries$Beliefs)
# 
# 
# obituaries$Text = tolower(obituaries$Text) #transform to lower case
# 
# 
# #Preprocess target text
# toks <- quanteda::tokens(obituaries$Text, remove_numbers = T, remove_punct = T, remove_symbols = T)
# 
# toks <- tokens_wordstem(toks, language = quanteda_options("language_stemmer"))
# 
# string_stemmed= vector()
# for(i in 1:length(toks)){
#   string_stemmed = rbind(string_stemmed, paste(toks[[i]], collapse=' '))
# }
```

Match text data to dictionaries and format

```{r}
# #Match target text to dictionaries
# toks_dict_pre <- tokens_lookup(toks, dictionary = Dicts_v2, levels = 1)
# 
# 
# #Transform to a document-feature dataframe
# toks_dict_pre = convert(dfm(toks_dict_pre), to = "data.frame")
# 
# 
# #Bind together
# toks_dict = cbind(toks_dict_pre,
#                   ntoken(toks), #raw count
#                   ntype(toks), #distinct count
#                   string_stemmed,
#                   obituaries)
# 
# 
# #Get percentage of words in the specific text that belong to each dictionary
# toks_dict = toks_dict %>%
#   mutate_at(vars(sociability_dic:appearance_dic), .funs = list(percent = ~(./`ntoken(toks)`)))
# 
# 
# #Get binary indicator: is dictionary in text or not?
# toks_dict = toks_dict %>%
#   mutate_at(vars(sociability_dic:appearance_dic), .funs = list(binary = ~ifelse(. > 0 , 1, 0)))
# 
# 
# #Create direction indicators
# toks_dict = toks_dict %>%
#   mutate(sociability_dir = sociability_dic_hi - sociability_dic_lo,
#          morality_dir = morality_dic_hi - morality_dic_lo,
#          ability_dir =  ability_dic_hi - ability_dic_lo,
#          assertiveness_dir = assertiveness_dic_hi - assertiveness_dic_lo,
#          status_dir = status_dic_hi - status_dic_lo,
#          warmth_dir = warmth_dic_hi - warmth_dic_lo,
#          competence_dir = competence_dic_hi - competence_dic_lo,
#          beliefs_dir = beliefs_dic_hi - beliefs_dic_lo
#          )
```

Write data

```{r}
#write.csv(toks_dict, "obituaries dict.csv")
```

Example analysis

```{r}
# Sociability_mod = lm(Sociability ~ sociability_dir,data =  toks_dict)
# summary(Sociability_mod)
```

#### Variables:

# _dic variables indicate how many words in the text were coded into that dimension, regardless of whether the response is high or low (e.g., for sociability, both friendly and unfriendly are counted)

# _dic_hi and _dic_lo variables indicate how many words in the text were coded as being high and low (respectively) on the dimension (if the word is not in the dimension, it is not counted here)

# _dic_percent is simply the _dic variable divided by the total number of words in the text (so, percentage of words in the text coded into the dimension)

# _dic_binary indicates whether the text includes the dimension at all, 0 = No, 1 = yes

# _dir indicates the direction of the dimension in the text. It is calculated as dic_hi - dic_lo, thus higher scores indicate more high-directional words in the text for that dimension, lower scores indicate more low-directional words in the text for that dimension. A score of 0 indicates either equal number of words in the dimension or no words related to the dimension (thus no directional bias).

#**** Please review paper to understand how the different dimensions are define and constructed, many overlap. (https://onlinelibrary.wiley.com/doi/10.1002/ejsp.2724)

